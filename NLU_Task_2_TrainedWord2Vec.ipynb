{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WillN202/NLU_CW/blob/main/NLU_Task_2_TrainedWord2Vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlQkoYuH5oNt"
      },
      "source": [
        "# NLU Task 2\n",
        "\n",
        "\n",
        "For this task I've implemented a GRU model using TODO word embeddings. TODO WRITE ME"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports and Setup"
      ],
      "metadata": {
        "id": "Gwcn-FvhbQbH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKJXDcr5WiuA",
        "outputId": "5e5418b2-e355-469e-daff-9f2694f0024c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.3.2-py3-none-any.whl (841 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/841.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.4/841.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m839.7/841.5 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m841.5/841.5 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.25.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.0)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.2.1+cu121)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.11.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.13.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics\n",
            "Successfully installed lightning-utilities-0.11.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 torchmetrics-1.3.2\n",
            "Collecting ray[tune]\n",
            "  Downloading ray-2.11.0-cp310-cp310-manylinux2014_x86_64.whl (65.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.3/65.3 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (3.13.4)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (4.19.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (1.0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (24.0)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (6.0.1)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (2.31.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (2.0.3)\n",
            "Collecting tensorboardX>=1.9 (from ray[tune])\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (14.0.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (2023.6.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pyarrow>=6.0.1->ray[tune]) (1.25.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]) (0.18.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->ray[tune]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ray[tune]) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ray[tune]) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->ray[tune]) (1.16.0)\n",
            "Installing collected packages: tensorboardX, ray\n",
            "Successfully installed ray-2.11.0 tensorboardX-2.6.2.2\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "!pip install torchmetrics\n",
        "!pip install ray[tune]\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qJ4fIPML5kK3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchmetrics\n",
        "import os.path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "from ray import tune, train\n",
        "from ray.tune.schedulers import ASHAScheduler\n",
        "from ray.tune.search.hyperopt import HyperOptSearch\n",
        "import string\n",
        "import re\n",
        "import gensim.downloader\n",
        "import tempfile\n",
        "import random\n",
        "TRAINING_DATASET_LOCATION = \"/content/drive/MyDrive/train.csv\"\n",
        "DEV_DATASET_LOCATION = \"/content/drive/MyDrive/dev.csv\"\n",
        "TEST_DATASET_LOCATION = \"/content/drive/MyDrive/AV_trial.csv\"\n",
        "WORD2VEC_EMBEDDINGS = \"/content/drive/MyDrive/word2vec_embeddings_tessty.model\"\n",
        "EPOCHS = 4\n",
        "\n",
        "DEVICE = (\n",
        "    \"cuda:0\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "# print(DEVICE)\n",
        "# torch.set_default_device(DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading and Pre Processing"
      ],
      "metadata": {
        "id": "7rqdPHc2bThB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tn7zuJQIAf7s"
      },
      "outputs": [],
      "source": [
        "def generic_preprocessor(sentence):\n",
        "  sentence = sentence.lower()\n",
        "\n",
        "  return sentence\n",
        "\n",
        "class AVDataset(Dataset):\n",
        "  def __init__(self, csv_file, pre_processor=None):\n",
        "    self.samples = pd.read_csv(csv_file)\n",
        "    self.pre_processor = pre_processor\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.samples)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    sample = self.samples.iloc[index]\n",
        "    # sample[0] = re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", sample[0])\n",
        "    # sample[0] = re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", sample[1])\n",
        "    sample_text = f\"{sample[0]} <sep> {sample[1]}\"\n",
        "    return (self.pre_processor(sample_text), sample[2])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "AaGl4cL1Af0W"
      },
      "outputs": [],
      "source": [
        "training_samples = AVDataset(TRAINING_DATASET_LOCATION, pre_processor=generic_preprocessor)\n",
        "dev_samples = AVDataset(DEV_DATASET_LOCATION, pre_processor=generic_preprocessor)\n",
        "test_samples = AVDataset(TEST_DATASET_LOCATION, pre_processor=generic_preprocessor)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word Embedding Generation"
      ],
      "metadata": {
        "id": "rlpJREJkbj5l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "o0UEKNyf-9h0"
      },
      "outputs": [],
      "source": [
        "def add_unk(phrase1, phrase2):\n",
        "  phrase1 = [\"<UNK>\" if random.random() < 0.05 else word for word in phrase1.split()]\n",
        "  phrase2 = [\"<UNK>\" if random.random() < 0.05 else word for word in phrase2.split()]\n",
        "\n",
        "  return [\"<pad>\"] * random.randint(1,15) + phrase1 + [\"<sep>\"] + phrase2\n",
        "\n",
        "\n",
        "def generate_word2vec_embeddings(size, phrases):\n",
        "  return Word2Vec(sentences=phrases, workers=300, min_count=1, vector_size=size)\n",
        "\n",
        "phrases = pd.read_csv(TRAINING_DATASET_LOCATION)\n",
        "phrases = phrases.loc[:, \"text_1\":\"text_2\"].to_numpy().flatten().tolist()\n",
        "phrases = [add_unk(str(phrases[i]), str(phrases[i+1])) for i in range(0, len(phrases), 2)]\n",
        "\n",
        "embeddings_512 = generate_word2vec_embeddings(512, phrases)\n",
        "embeddings_256 = generate_word2vec_embeddings(256, phrases)\n",
        "embeddings_128 = generate_word2vec_embeddings(128, phrases)\n",
        "embeddings_64 = generate_word2vec_embeddings(64, phrases)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Creation\n",
        "\n",
        "To reduce code content, the GRU models are defined from a base class. New linear layers are added between each class of model since this could not be done using parameters alone"
      ],
      "metadata": {
        "id": "8hQ7fpZVbvAl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PrrTcF4NMoRB"
      },
      "outputs": [],
      "source": [
        "class BaseGruRNN(torch.nn.Module):\n",
        "  def __init__(self, embedding_size, output_size, hidden_size, embeddings, vocab, rnn_layers=1, is_bidirectional=False):\n",
        "    super(BaseGruRNN, self).__init__()\n",
        "    self.vocab = vocab\n",
        "    self.get_embedding = torch.nn.Embedding.from_pretrained(embeddings)\n",
        "    self.GRU_Layer = torch.nn.GRU(embedding_size, hidden_size, batch_first=True, num_layers=rnn_layers, dropout=0.1, bidirectional=is_bidirectional)\n",
        "\n",
        "  def forward(self, x, linear_layer):\n",
        "    unk_embedding = self.vocab[\"<UNK>\"]\n",
        "    #x = [re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", sentence) for sentence in x]\n",
        "    x = [sentence.split() for sentence in x]\n",
        "    x = [[self.vocab.get(word, unk_embedding) for word in sentence ] for sentence in x]\n",
        "    # TODO -> instead of padding, use pack sequence instead. Note this may break the output from the lstm (woo)\n",
        "    max_len = max([len(words) for words in x])\n",
        "    x = [([self.vocab[\"<pad>\"]] * (max_len -  len(words))) + words for words in x]\n",
        "    input = torch.tensor(x)\n",
        "\n",
        "    embeddings = self.get_embedding(input)\n",
        "    GRU_int_results = self.GRU_Layer(embeddings)[1]\n",
        "    GRU_values = GRU_int_results[0] #Get last hidden state(s)\n",
        "    result = linear_layer(GRU_values)\n",
        "    return result\n",
        "\n",
        "class OneLinearLayerGruRNN(BaseGruRNN):\n",
        "    def __init__(self, embedding_size, output_size, hidden_size, embeddings, vocab, rnn_layers=1, is_bidirectional=False):\n",
        "      self.base = super(OneLinearLayerGruRNN, self).__init__(embedding_size, output_size, hidden_size, embeddings, vocab, rnn_layers, is_bidirectional)\n",
        "      self.linear_layer = torch.nn.Sequential(\n",
        "          torch.nn.Linear(hidden_size, output_size),\n",
        "      )\n",
        "\n",
        "    def forward(self, x):\n",
        "      return super().forward(x, self.linear_layer)\n",
        "\n",
        "class TwoLinearLayerGruRNN(BaseGruRNN):\n",
        "    def __init__(self, embedding_size, output_size, hidden_size, embeddings, vocab, rnn_layers=1, is_bidirectional=False):\n",
        "      super().__init__(embedding_size, output_size, hidden_size, embeddings, vocab, rnn_layers, is_bidirectional)\n",
        "      self.linear_layer = torch.nn.Sequential(\n",
        "          torch.nn.Linear(hidden_size, hidden_size),\n",
        "          torch.nn.LeakyReLU(),\n",
        "          torch.nn.Dropout(p=0.1),\n",
        "          torch.nn.Linear(hidden_size, output_size)\n",
        "      )\n",
        "\n",
        "    def forward(self, x):\n",
        "      return super().forward(x, self.linear_layer)\n",
        "\n",
        "class ThreeLinearLayerGruRNN(BaseGruRNN):\n",
        "    def __init__(self, embedding_size, output_size, hidden_size, embeddings, vocab, rnn_layers=1, is_bidirectional=False):\n",
        "      super(ThreeLinearLayerGruRNN, self).__init__(embedding_size, output_size, hidden_size, embeddings, vocab, rnn_layers, is_bidirectional)\n",
        "      self.linear_layer = torch.nn.Sequential(\n",
        "          torch.nn.Linear(hidden_size, hidden_size),\n",
        "          torch.nn.LeakyReLU(),\n",
        "          torch.nn.Dropout(p=0.1),\n",
        "          torch.nn.Linear(hidden_size, hidden_size),\n",
        "          torch.nn.LeakyReLU(),\n",
        "          torch.nn.Dropout(p=0.1),\n",
        "          torch.nn.Linear(hidden_size, output_size)\n",
        "      )\n",
        "\n",
        "    def forward(self, x):\n",
        "      return super().forward(x, self.linear_layer)\n",
        "\n",
        "class FourLinearLayerGruRNN(BaseGruRNN):\n",
        "    def __init__(self, embedding_size, output_size, hidden_size, embeddings, vocab, rnn_layers=1, is_bidirectional=False):\n",
        "      super(FourLinearLayerGruRNN, self).__init__(embedding_size, output_size, hidden_size, embeddings, vocab, rnn_layers, is_bidirectional)\n",
        "      self.linear_layer = torch.nn.Sequential(\n",
        "          torch.nn.Linear(hidden_size, hidden_size),\n",
        "          torch.nn.LeakyReLU(),\n",
        "          torch.nn.Dropout(p=0.1),\n",
        "          torch.nn.Linear(hidden_size, hidden_size),\n",
        "          torch.nn.LeakyReLU(),\n",
        "          torch.nn.Dropout(p=0.1),\n",
        "          torch.nn.Linear(hidden_size, hidden_size),\n",
        "          torch.nn.LeakyReLU(),\n",
        "          torch.nn.Dropout(p=0.1),\n",
        "          torch.nn.Linear(hidden_size, output_size)\n",
        "      )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "      return super().forward(x, self.linear_layer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mD5m9thfWdI3"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "AsUf75tOWdI3"
      },
      "outputs": [],
      "source": [
        "def train_and_validate_loop(model, batch_size, learning_rate, epochs, tuning=False):\n",
        "  device = (\n",
        "    \"cuda:0\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "  torch.set_default_device(device)\n",
        "  loss_function = torch.nn.BCEWithLogitsLoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "  training_loader = DataLoader(training_samples, batch_size=batch_size, generator=torch.Generator(device=device))\n",
        "  dev_loader = DataLoader(dev_samples, batch_size=batch_size, generator=torch.Generator(device=device))\n",
        "  accuracy = torchmetrics.Accuracy(task=\"binary\")\n",
        "  f1_score = torchmetrics.F1Score(task=\"binary\")\n",
        "  torch.set_grad_enabled(True)\n",
        "\n",
        "  if not tuning:\n",
        "    print(f\"Epochs: {epochs}\")\n",
        "\n",
        "  for epoch in range(0, epochs):\n",
        "      model.train()\n",
        "      running_loss = 0.0\n",
        "\n",
        "      # Training\n",
        "      for index, value in enumerate(training_loader):\n",
        "          optimizer.zero_grad()\n",
        "          data, labels = value\n",
        "          labels = labels.reshape(-1,1)\n",
        "          labels = labels.type(torch.FloatTensor)\n",
        "          labels = labels.to(device)\n",
        "          outputs = model(data)\n",
        "\n",
        "          loss = loss_function(outputs, labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          running_loss += loss.item()\n",
        "\n",
        "      # Validation to ensure the model is learning\n",
        "      model.eval()\n",
        "      torch.set_grad_enabled(False)\n",
        "      running_loss = 0\n",
        "      num_correct = 0\n",
        "\n",
        "      pred = torch.Tensor().to(device)\n",
        "      gold_standard = torch.Tensor().to(device)\n",
        "      for index, value in enumerate(dev_loader):\n",
        "          data, labels = value\n",
        "          labels = labels.reshape(-1,1)\n",
        "          labels = labels.type(torch.FloatTensor)\n",
        "          labels = labels.to(device)\n",
        "\n",
        "          outputs = model(data)\n",
        "          loss = loss_function(outputs, labels)\n",
        "          running_loss += loss\n",
        "\n",
        "          normalised_outputs = torch.sigmoid(outputs)\n",
        "          pred = torch.cat((pred, normalised_outputs))\n",
        "          gold_standard = torch.cat((gold_standard, labels))\n",
        "\n",
        "      torch.set_grad_enabled(True)\n",
        "      batch_loss = running_loss / len(dev_loader)\n",
        "      score = f1_score(pred, gold_standard)\n",
        "      with tempfile.TemporaryDirectory() as temp_checkpoint_dir:\n",
        "        checkpoint = None\n",
        "        if (epoch + 1) % 3 == 0:\n",
        "            # This saves the model to the trial directory\n",
        "            torch.save(\n",
        "                model.state_dict(),\n",
        "                os.path.join(temp_checkpoint_dir, \"model.pth\")\n",
        "            )\n",
        "            checkpoint = train.Checkpoint.from_directory(temp_checkpoint_dir)\n",
        "\n",
        "        if tuning:\n",
        "          train.report({\"score\": float(score)}, checkpoint=checkpoint)\n",
        "        else:\n",
        "          print(f\"---------------------EPOCH {epoch+1} / {epochs}---------------------\")\n",
        "          print(f\"Batch Loss {batch_loss}\")\n",
        "          print(f\"Accuracy {accuracy(pred, gold_standard)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test_embeddings = gensim.downloader.load(\"word2vec-google-news-300\")\n",
        "# test_embeddings[\"<UNK>\"] = np.random.rand(300)\n",
        "# test_embeddings[\"<sep>\"] = np.random.rand(300)\n",
        "# test_embeddings[\"<pad>\"] = np.random.rand(300)\n",
        "# coded_embeddings = torch.FloatTensor(test_embeddings.vectors).to(DEVICE)\n",
        "# vocab = test_embeddings.key_to_index\n",
        "# model = FourLinearLayerGruRNN(300, 1, 300, coded_embeddings, vocab, 1, is_bidirectional=True).to(DEVICE)\n",
        "# train_and_validate_loop(model,64, 0.000019238, 3)"
      ],
      "metadata": {
        "id": "GwFkpGRiIy4Q"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter Selection"
      ],
      "metadata": {
        "id": "XLxTiuHm9eWk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tune_training_step(config, embedding, network):\n",
        "  device = (\n",
        "    \"cuda:0\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "\n",
        "  chosen_network = network[config[\"linear_layers\"]]\n",
        "  embedding = embedding[config[\"embedding_size\"]]\n",
        "  coded_embeddings = torch.FloatTensor(np.array(embedding.wv.vectors)).to(device)\n",
        "  vocab = embedding.wv.key_to_index\n",
        "  generated_model = chosen_network(config[\"embedding_size\"], 1, config[\"embedding_size\"], coded_embeddings, vocab, config[\"rnn_layers\"], config[\"is_bidirectional\"]).to(device)\n",
        "  train_and_validate_loop(generated_model, config[\"batch_size\"], config[\"lr\"], config[\"epochs\"], True)\n",
        "\n",
        "\n",
        "config = {\n",
        "  \"lr\": tune.loguniform(1e-6, 1),\n",
        "  \"batch_size\": tune.choice([8, 16, 32, 64, 128]),\n",
        "  \"is_bidirectional\": tune.choice([True, False]),\n",
        "  \"epochs\": tune.choice(list(range(3,15))),\n",
        "  \"linear_layers\": tune.choice(list(range(1,5))),\n",
        "  \"rnn_layers\": tune.choice(list(range(1,5))),\n",
        "  \"embedding_size\": tune.choice([64,128,256,512]),\n",
        "  # \"hidden_size\": tune.choice(list(range(32, 513, 32)))\n",
        "}\n",
        "\n",
        "\n",
        "embedding = {\n",
        "    64: embeddings_64,\n",
        "    128: embeddings_128,\n",
        "    256: embeddings_256,\n",
        "    512: embeddings_512\n",
        "}\n",
        "\n",
        "network = {\n",
        "    1: OneLinearLayerGruRNN,\n",
        "    2: TwoLinearLayerGruRNN,\n",
        "    3: ThreeLinearLayerGruRNN,\n",
        "    4: FourLinearLayerGruRNN\n",
        "}\n",
        "\n",
        "asha_scheduler = ASHAScheduler(\n",
        "        metric=\"score\",\n",
        "        mode=\"max\",\n",
        "        max_t=14,\n",
        "        grace_period=2,\n",
        "        reduction_factor=2\n",
        "    )\n",
        "\n",
        "chosen_search_alg = HyperOptSearch(metric=\"score\", mode=\"max\")\n",
        "\n",
        "training_wrapper = tune.with_resources(tune.with_parameters(tune_training_step, embedding=embedding, network=network), {\"CPU\": 1.6, \"GPU\": 1/3})\n",
        "tuner = tune.Tuner(\n",
        "    training_wrapper,\n",
        "    tune_config=tune.TuneConfig(\n",
        "        num_samples=35,\n",
        "        search_alg=chosen_search_alg,\n",
        "        scheduler=asha_scheduler,\n",
        "    ),\n",
        "    param_space=config\n",
        ")\n",
        "\n",
        "result = tuner.fit()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPHj0OBN9h0l",
        "outputId": "edb8a7f2-de1f-4434-c269-62bd9acc0e8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-04-23 20:00:33,655\tINFO tune.py:633 -- [output] This will use the new output engine with verbosity 1. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------------------------------+\n",
            "| Configuration for experiment     tune_training_step_2024-04-23_20-00-33   |\n",
            "+---------------------------------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator                          |\n",
            "| Scheduler                        AsyncHyperBandScheduler                  |\n",
            "| Number of trials                 35                                       |\n",
            "+---------------------------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /root/ray_results/tune_training_step_2024-04-23_20-00-33\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2024-04-23_19-40-33_543663_216/artifacts/2024-04-23_20-00-33/tune_training_step_2024-04-23_20-00-33/driver_artifacts`\n",
            "\u001b[33m(raylet)\u001b[0m Warning: The actor ImplicitFunc is very large (38 MiB). Check that its definition is not implicitly capturing a large array or other object in scope. Tip: use ray.put() to put large objects in the Ray object store.\n",
            "\n",
            "Trial status: 1 PENDING\n",
            "Current time: 2024-04-23 20:00:34. Total running time: 0s\n",
            "Logical resource usage: 1.6/16 CPUs, 0.3333333333333333/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                    status             lr     batch_size   is_bidirectional       epochs     linear_layers     rnn_layers     embedding_size |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| tune_training_step_70f694f8   PENDING    0.00947685             64   False                      12                 2              4                128 |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial tune_training_step_70f694f8 started with configuration:\n",
            "+------------------------------------------------------+\n",
            "| Trial tune_training_step_70f694f8 config             |\n",
            "+------------------------------------------------------+\n",
            "| batch_size                                        64 |\n",
            "| embedding_size                                   128 |\n",
            "| epochs                                            12 |\n",
            "| is_bidirectional                                   0 |\n",
            "| linear_layers                                      2 |\n",
            "| lr                                           0.00948 |\n",
            "| rnn_layers                                         4 |\n",
            "+------------------------------------------------------+\n",
            "\n",
            "Trial tune_training_step_16993d85 started with configuration:\n",
            "+------------------------------------------------------+\n",
            "| Trial tune_training_step_16993d85 config             |\n",
            "+------------------------------------------------------+\n",
            "| batch_size                                       128 |\n",
            "| embedding_size                                   256 |\n",
            "| epochs                                            10 |\n",
            "| is_bidirectional                                   0 |\n",
            "| linear_layers                                      1 |\n",
            "| lr                                           0.01539 |\n",
            "| rnn_layers                                         1 |\n",
            "+------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(tune_training_step pid=29181)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "\u001b[36m(tune_training_step pid=29181)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial tune_training_step_eaa60734 started with configuration:\n",
            "+------------------------------------------------------+\n",
            "| Trial tune_training_step_eaa60734 config             |\n",
            "+------------------------------------------------------+\n",
            "| batch_size                                         8 |\n",
            "| embedding_size                                   512 |\n",
            "| epochs                                            11 |\n",
            "| is_bidirectional                                   0 |\n",
            "| linear_layers                                      4 |\n",
            "| lr                                           0.42617 |\n",
            "| rnn_layers                                         3 |\n",
            "+------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation"
      ],
      "metadata": {
        "id": "j2lNCqWQ1HYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_result = result.get_best_result(\"loss\", mode=\"min\")\n",
        "with best_result.checkpoint.as_directory() as checkpoint_dir:\n",
        "    state_dict = torch.load(os.path.join(checkpoint_dir, \"model.pth\"))\n",
        "\n",
        "print(best_result)"
      ],
      "metadata": {
        "id": "rrnXbCrU8tFK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6bebcc9-26b1-4167-f2f7-e6790ce1aca4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result(\n",
            "  metrics={'loss': 0.6928823590278625},\n",
            "  path='/root/ray_results/tune_training_step_2024-04-23_17-59-11/tune_training_step_9b7af96a_5_batch_size=128,epochs=4,is_bidirectional=False,linear_layers=1,lr=0.0000,rnn_layers=4_2024-04-23_18-05-05',\n",
            "  filesystem='local',\n",
            "  checkpoint=Checkpoint(filesystem=local, path=/root/ray_results/tune_training_step_2024-04-23_17-59-11/tune_training_step_9b7af96a_5_batch_size=128,epochs=4,is_bidirectional=False,linear_layers=1,lr=0.0000,rnn_layers=4_2024-04-23_18-05-05/checkpoint_000000)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coded_embeddings = torch.FloatTensor(chosen_embedding.vectors).to(DEVICE)\n",
        "vocab = chosen_embedding.key_to_index\n",
        "model = OneLinearLayerGruRNN(300, 1, 300, coded_embeddings, vocab, 4, is_bidirectional=False).to(DEVICE)\n",
        "model.load_state_dict(state_dict)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErmSN1bowkQ0",
        "outputId": "c529903a-aab2-4f4b-b78e-a00c01b3adc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "torch.set_default_device(DEVICE)\n",
        "torch.set_grad_enabled(False)\n",
        "num_correct = 0\n",
        "loader = DataLoader(test_samples, batch_size=16, generator=torch.Generator(device=DEVICE))\n",
        "\n",
        "answers = torch.Tensor().to(DEVICE)\n",
        "gold_standard = torch.Tensor().to(DEVICE)\n",
        "\n",
        "for index, value in enumerate(loader):\n",
        "    data, labels = value\n",
        "    labels = labels.reshape(-1,1)\n",
        "    labels = labels.type(torch.FloatTensor)\n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    outputs = model(data)\n",
        "\n",
        "    answers = torch.cat((answers, outputs))\n",
        "    gold_standard = torch.cat((gold_standard, labels))\n",
        "\n",
        "\n",
        "torch.set_grad_enabled(True)\n",
        "accuracy = torchmetrics.Accuracy(task=\"binary\")\n",
        "mcc = torchmetrics.MatthewsCorrCoef(task=\"binary\")\n",
        "print(f\"Accuracy {accuracy(answers, gold_standard)}\")\n",
        "print(f\"MCC {mcc(answers, gold_standard)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqKXBPT7zQn9",
        "outputId": "fafe68fd-1359-47ea-a1a3-9bbaba889a45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.4399999976158142\n",
            "MCC -0.13093073666095734\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}