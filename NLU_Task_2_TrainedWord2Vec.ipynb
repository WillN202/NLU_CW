{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WillN202/NLU_CW/blob/main/NLU_Task_2_TrainedWord2Vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlQkoYuH5oNt"
      },
      "source": [
        "# NLU Task 2\n",
        "\n",
        "\n",
        "For this task I've implemented a GRU model using TODO word embeddings. TODO WRITE ME"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports and Setup"
      ],
      "metadata": {
        "id": "Gwcn-FvhbQbH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKJXDcr5WiuA",
        "outputId": "94d94053-0ddf-4a75-b0ec-b9c01be41e23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.3.2-py3-none-any.whl (841 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/841.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.4/841.5 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m839.7/841.5 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m841.5/841.5 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.25.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.0)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.2.1+cu121)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.11.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.13.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics\n",
            "Successfully installed lightning-utilities-0.11.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 torchmetrics-1.3.2\n",
            "Collecting ray[tune]\n",
            "  Downloading ray-2.11.0-cp310-cp310-manylinux2014_x86_64.whl (65.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.3/65.3 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (3.13.4)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (4.19.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (1.0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (24.0)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (6.0.1)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (2.31.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (2.0.3)\n",
            "Collecting tensorboardX>=1.9 (from ray[tune])\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (14.0.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (2023.6.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pyarrow>=6.0.1->ray[tune]) (1.25.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]) (0.18.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->ray[tune]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ray[tune]) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ray[tune]) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->ray[tune]) (1.16.0)\n",
            "Installing collected packages: tensorboardX, ray\n",
            "Successfully installed ray-2.11.0 tensorboardX-2.6.2.2\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "!pip install torchmetrics\n",
        "!pip install ray[tune]\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJ4fIPML5kK3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchmetrics\n",
        "import os.path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "from ray import tune, train\n",
        "from ray.tune.schedulers import ASHAScheduler\n",
        "from ray.tune.search.hyperopt import HyperOptSearch\n",
        "import string\n",
        "import re\n",
        "import gensim.downloader\n",
        "import tempfile\n",
        "TRAINING_DATASET_LOCATION = \"/content/drive/MyDrive/train.csv\"\n",
        "DEV_DATASET_LOCATION = \"/content/drive/MyDrive/dev.csv\"\n",
        "TEST_DATASET_LOCATION = \"/content/drive/MyDrive/AV_trial.csv\"\n",
        "WORD2VEC_EMBEDDINGS = \"/content/drive/MyDrive/word2vec_embeddings_tessty.model\"\n",
        "EPOCHS = 4\n",
        "\n",
        "DEVICE = (\n",
        "    \"cuda:0\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "# print(DEVICE)\n",
        "# torch.set_default_device(DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading and Pre Processing"
      ],
      "metadata": {
        "id": "7rqdPHc2bThB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tn7zuJQIAf7s"
      },
      "outputs": [],
      "source": [
        "def generic_preprocessor(sentence):\n",
        "  sentence = sentence.lower()\n",
        "\n",
        "  return sentence\n",
        "\n",
        "class AVDataset(Dataset):\n",
        "  def __init__(self, csv_file, pre_processor=None):\n",
        "    self.samples = pd.read_csv(csv_file)\n",
        "    self.pre_processor = pre_processor\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.samples)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    sample = self.samples.iloc[index]\n",
        "    # sample[0] = re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", sample[0])\n",
        "    # sample[0] = re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", sample[1])\n",
        "    sample_text = f\"{sample[0]} <sep> {sample[1]}\"\n",
        "    return (self.pre_processor(sample_text), sample[2])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AaGl4cL1Af0W"
      },
      "outputs": [],
      "source": [
        "training_samples = AVDataset(TRAINING_DATASET_LOCATION, pre_processor=generic_preprocessor)\n",
        "dev_samples = AVDataset(DEV_DATASET_LOCATION, pre_processor=generic_preprocessor)\n",
        "test_samples = AVDataset(TEST_DATASET_LOCATION, pre_processor=generic_preprocessor)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word Embedding Generation"
      ],
      "metadata": {
        "id": "rlpJREJkbj5l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0UEKNyf-9h0"
      },
      "outputs": [],
      "source": [
        "phrases = pd.read_csv(TRAINING_DATASET_LOCATION)\n",
        "phrases = phrases.loc[:, \"text_1\":\"text_2\"].to_numpy().flatten().tolist()\n",
        "#phrases = [re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", str(phrase)).split() for phrase in phrases]\n",
        "phrases = [str(phrase).split() for phrase in phrases]\n",
        "\n",
        "def generate_word2vec_embeddings(size):\n",
        "  embeddings = Word2Vec(sentences=phrases, workers=300, min_count=1, vector_size=size)\n",
        "  embeddings.wv[\"<UNK>\"] = np.random.rand(size)\n",
        "  embeddings.wv[\"<sep>\"] = np.random.rand(size)\n",
        "  embeddings.wv[\"<pad>\"] = np.random.rand(size)\n",
        "\n",
        "  return embeddings\n",
        "\n",
        "\n",
        "embeddings_512 = generate_word2vec_embeddings(512)\n",
        "embeddings_256 = generate_word2vec_embeddings(256)\n",
        "embeddings_128 = generate_word2vec_embeddings(128)\n",
        "embeddings_64 = generate_word2vec_embeddings(64)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Creation\n",
        "\n",
        "To reduce code content, the GRU models are defined from a base class. New linear layers are added between each class of model since this could not be done using parameters alone"
      ],
      "metadata": {
        "id": "8hQ7fpZVbvAl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrrTcF4NMoRB"
      },
      "outputs": [],
      "source": [
        "class BaseGruRNN(torch.nn.Module):\n",
        "  def __init__(self, embedding_size, output_size, hidden_size, embeddings, vocab, rnn_layers=1, is_bidirectional=False):\n",
        "    super(BaseGruRNN, self).__init__()\n",
        "    self.vocab = vocab\n",
        "    self.get_embedding = torch.nn.Embedding.from_pretrained(embeddings)\n",
        "    self.GRU_Layer = torch.nn.GRU(embedding_size, hidden_size, batch_first=True, num_layers=rnn_layers, dropout=0.1, bidirectional=is_bidirectional)\n",
        "\n",
        "  def forward(self, x, linear_layer):\n",
        "    unk_embedding = self.vocab[\"<UNK>\"]\n",
        "    #x = [re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", sentence) for sentence in x]\n",
        "    x = [sentence.split() for sentence in x]\n",
        "    x = [[self.vocab.get(word, unk_embedding) for word in sentence ] for sentence in x]\n",
        "    # TODO -> instead of padding, use pack sequence instead. Note this may break the output from the lstm (woo)\n",
        "    max_len = max([len(words) for words in x])\n",
        "    x = [([self.vocab[\"<pad>\"]] * (max_len -  len(words))) + words for words in x]\n",
        "    input = torch.tensor(x)\n",
        "\n",
        "    embeddings = self.get_embedding(input)\n",
        "    GRU_int_results = self.GRU_Layer(embeddings)[1]\n",
        "    GRU_values = GRU_int_results[0] #Get last hidden state(s)\n",
        "    result = linear_layer(GRU_values)\n",
        "    return result\n",
        "\n",
        "class OneLinearLayerGruRNN(BaseGruRNN):\n",
        "    def __init__(self, embedding_size, output_size, hidden_size, embeddings, vocab, rnn_layers=1, is_bidirectional=False):\n",
        "      self.base = super(OneLinearLayerGruRNN, self).__init__(embedding_size, output_size, hidden_size, embeddings, vocab, rnn_layers, is_bidirectional)\n",
        "      self.linear_layer = torch.nn.Sequential(\n",
        "          torch.nn.Linear(hidden_size, output_size),\n",
        "      )\n",
        "\n",
        "    def forward(self, x):\n",
        "      return super().forward(x, self.linear_layer)\n",
        "\n",
        "class TwoLinearLayerGruRNN(BaseGruRNN):\n",
        "    def __init__(self, embedding_size, output_size, hidden_size, embeddings, vocab, rnn_layers=1, is_bidirectional=False):\n",
        "      super().__init__(embedding_size, output_size, hidden_size, embeddings, vocab, rnn_layers, is_bidirectional)\n",
        "      self.linear_layer = torch.nn.Sequential(\n",
        "          torch.nn.Linear(hidden_size, hidden_size),\n",
        "          torch.nn.LeakyReLU(),\n",
        "          torch.nn.Dropout(p=0.1),\n",
        "          torch.nn.Linear(hidden_size, output_size)\n",
        "      )\n",
        "\n",
        "    def forward(self, x):\n",
        "      return super().forward(x, self.linear_layer)\n",
        "\n",
        "class ThreeLinearLayerGruRNN(BaseGruRNN):\n",
        "    def __init__(self, embedding_size, output_size, hidden_size, embeddings, vocab, rnn_layers=1, is_bidirectional=False):\n",
        "      super(ThreeLinearLayerGruRNN, self).__init__(embedding_size, output_size, hidden_size, embeddings, vocab, rnn_layers, is_bidirectional)\n",
        "      self.linear_layer = torch.nn.Sequential(\n",
        "          torch.nn.Linear(hidden_size, hidden_size),\n",
        "          torch.nn.LeakyReLU(),\n",
        "          torch.nn.Dropout(p=0.1),\n",
        "          torch.nn.Linear(hidden_size, hidden_size),\n",
        "          torch.nn.LeakyReLU(),\n",
        "          torch.nn.Dropout(p=0.1),\n",
        "          torch.nn.Linear(hidden_size, output_size)\n",
        "      )\n",
        "\n",
        "    def forward(self, x):\n",
        "      return super().forward(x, self.linear_layer)\n",
        "\n",
        "class FourLinearLayerGruRNN(BaseGruRNN):\n",
        "    def __init__(self, embedding_size, output_size, hidden_size, embeddings, vocab, rnn_layers=1, is_bidirectional=False):\n",
        "      super(FourLinearLayerGruRNN, self).__init__(embedding_size, output_size, hidden_size, embeddings, vocab, rnn_layers, is_bidirectional)\n",
        "      self.linear_layer = torch.nn.Sequential(\n",
        "          torch.nn.Linear(hidden_size, hidden_size),\n",
        "          torch.nn.LeakyReLU(),\n",
        "          torch.nn.Dropout(p=0.1),\n",
        "          torch.nn.Linear(hidden_size, hidden_size),\n",
        "          torch.nn.LeakyReLU(),\n",
        "          torch.nn.Dropout(p=0.1),\n",
        "          torch.nn.Linear(hidden_size, hidden_size),\n",
        "          torch.nn.LeakyReLU(),\n",
        "          torch.nn.Dropout(p=0.1),\n",
        "          torch.nn.Linear(hidden_size, output_size)\n",
        "      )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "      return super().forward(x, self.linear_layer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mD5m9thfWdI3"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsUf75tOWdI3"
      },
      "outputs": [],
      "source": [
        "def train_and_validate_loop(model, batch_size, learning_rate, epochs, tuning=False):\n",
        "  device = (\n",
        "    \"cuda:0\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "  torch.set_default_device(device)\n",
        "  loss_function = torch.nn.BCEWithLogitsLoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "  training_loader = DataLoader(training_samples, batch_size=batch_size, generator=torch.Generator(device=device))\n",
        "  dev_loader = DataLoader(dev_samples, batch_size=batch_size, generator=torch.Generator(device=device))\n",
        "  accuracy = torchmetrics.Accuracy(task=\"binary\")\n",
        "  f1_score = torchmetrics.F1Score(task=\"binary\")\n",
        "  torch.set_grad_enabled(True)\n",
        "\n",
        "  if not tuning:\n",
        "    print(f\"Epochs: {epochs}\")\n",
        "\n",
        "  for epoch in range(0, epochs):\n",
        "      model.train()\n",
        "      running_loss = 0.0\n",
        "\n",
        "      # Training\n",
        "      for index, value in enumerate(training_loader):\n",
        "          optimizer.zero_grad()\n",
        "          data, labels = value\n",
        "          labels = labels.reshape(-1,1)\n",
        "          labels = labels.type(torch.FloatTensor)\n",
        "          labels = labels.to(device)\n",
        "          outputs = model(data)\n",
        "\n",
        "          loss = loss_function(outputs, labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          running_loss += loss.item()\n",
        "\n",
        "      # Validation to ensure the model is learning\n",
        "      model.eval()\n",
        "      torch.set_grad_enabled(False)\n",
        "      running_loss = 0\n",
        "      num_correct = 0\n",
        "\n",
        "      pred = torch.Tensor().to(device)\n",
        "      gold_standard = torch.Tensor().to(device)\n",
        "      for index, value in enumerate(dev_loader):\n",
        "          data, labels = value\n",
        "          labels = labels.reshape(-1,1)\n",
        "          labels = labels.type(torch.FloatTensor)\n",
        "          labels = labels.to(device)\n",
        "\n",
        "          outputs = model(data)\n",
        "          loss = loss_function(outputs, labels)\n",
        "          running_loss += loss\n",
        "\n",
        "          normalised_outputs = torch.sigmoid(outputs)\n",
        "          pred = torch.cat((pred, normalised_outputs))\n",
        "          gold_standard = torch.cat((gold_standard, labels))\n",
        "\n",
        "      torch.set_grad_enabled(True)\n",
        "      batch_loss = running_loss / len(dev_loader)\n",
        "      score = f1_score(pred, gold_standard)\n",
        "      with tempfile.TemporaryDirectory() as temp_checkpoint_dir:\n",
        "        checkpoint = None\n",
        "        if (epoch + 1) % 3 == 0:\n",
        "            # This saves the model to the trial directory\n",
        "            torch.save(\n",
        "                model.state_dict(),\n",
        "                os.path.join(temp_checkpoint_dir, \"model.pth\")\n",
        "            )\n",
        "            checkpoint = train.Checkpoint.from_directory(temp_checkpoint_dir)\n",
        "\n",
        "        if tuning:\n",
        "          train.report({\"score\": score}, checkpoint=checkpoint)\n",
        "        else:\n",
        "          print(f\"---------------------EPOCH {epoch+1} / {epochs}---------------------\")\n",
        "          print(f\"Batch Loss {batch_loss}\")\n",
        "          print(f\"Accuracy {accuracy(pred, gold_standard)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test_embeddings = gensim.downloader.load(\"word2vec-google-news-300\")\n",
        "# test_embeddings[\"<UNK>\"] = np.random.rand(300)\n",
        "# test_embeddings[\"<sep>\"] = np.random.rand(300)\n",
        "# test_embeddings[\"<pad>\"] = np.random.rand(300)\n",
        "# coded_embeddings = torch.FloatTensor(test_embeddings.vectors).to(DEVICE)\n",
        "# vocab = test_embeddings.key_to_index\n",
        "# model = FourLinearLayerGruRNN(300, 1, 300, coded_embeddings, vocab, 1, is_bidirectional=True).to(DEVICE)\n",
        "# train_and_validate_loop(model,64, 0.000019238, 3)"
      ],
      "metadata": {
        "id": "GwFkpGRiIy4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter Selection"
      ],
      "metadata": {
        "id": "XLxTiuHm9eWk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tune_training_step(config, embedding, network):\n",
        "  device = (\n",
        "    \"cuda:0\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "\n",
        "  chosen_network = network[config[\"linear_layers\"]]\n",
        "  coded_embeddings = torch.FloatTensor(np.array(embedding.vectors)).to(device)\n",
        "  vocab = embedding.key_to_index\n",
        "  generated_model = chosen_network(300, 1, 300, coded_embeddings, vocab, config[\"rnn_layers\"], config[\"is_bidirectional\"]).to(device)\n",
        "  train_and_validate_loop(generated_model, config[\"batch_size\"], config[\"lr\"], config[\"epochs\"], True)\n",
        "\n",
        "\n",
        "config = {\n",
        "  \"lr\": tune.loguniform(1e-6, 1e-2),\n",
        "  \"batch_size\": tune.choice([8, 16, 32, 64, 128]),\n",
        "  \"is_bidirectional\": tune.choice([True, False]),\n",
        "  \"epochs\": tune.choice(list(range(3,15))),\n",
        "  \"linear_layers\": tune.choice(list(range(1,5))),\n",
        "  \"rnn_layers\": tune.choice(list(range(1,5))),\n",
        "  # \"embedding_size\": tune.choice([64,128,256,512]),\n",
        "  # \"hidden_size\": tune.choice(list(range(32, 513, 32)))\n",
        "}\n",
        "\n",
        "\n",
        "embedding = {\n",
        "    64: embeddings_64,\n",
        "    128: embeddings_128,\n",
        "    256: embeddings_256,\n",
        "    512: embeddings_512\n",
        "}\n",
        "\n",
        "network = {\n",
        "    1: OneLinearLayerGruRNN,\n",
        "    2: TwoLinearLayerGruRNN,\n",
        "    3: ThreeLinearLayerGruRNN,\n",
        "    4: FourLinearLayerGruRNN\n",
        "}\n",
        "\n",
        "asha_scheduler = ASHAScheduler(\n",
        "        metric=\"score\",\n",
        "        mode=\"max\",\n",
        "        max_t=14,\n",
        "        grace_period=2,\n",
        "        reduction_factor=2\n",
        "    )\n",
        "\n",
        "chosen_search_alg = HyperOptSearch(metric=\"score\", mode=\"max\")\n",
        "\n",
        "chosen_embedding = gensim.downloader.load(\"word2vec-google-news-300\")\n",
        "chosen_embedding.save(WORD2VEC_EMBEDDINGS)\n",
        "chosen_embedding[\"<UNK>\"] = np.random.rand(300)\n",
        "chosen_embedding[\"<sep>\"] = np.random.rand(300)\n",
        "chosen_embedding[\"<pad>\"] = np.random.rand(300)\n",
        "\n",
        "training_wrapper = tune.with_resources(tune.with_parameters(tune_training_step, embedding=chosen_embedding, network=network), {\"CPU\": 1.6, \"GPU\": 1/3})\n",
        "tuner = tune.Tuner(\n",
        "    training_wrapper,\n",
        "    tune_config=tune.TuneConfig(\n",
        "        num_samples=35,\n",
        "        search_alg=chosen_search_alg,\n",
        "        scheduler=asha_scheduler,\n",
        "    ),\n",
        "    param_space=config\n",
        ")\n",
        "\n",
        "result = tuner.fit()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "fPHj0OBN9h0l",
        "outputId": "cd6b0738-b7b7-4ff5-ad7c-599b3f95c582"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-3f33ff21d1fc>\u001b[0m in \u001b[0;36m<cell line: 51>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mchosen_search_alg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHyperOptSearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"score\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"max\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mchosen_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word2vec-google-news-300\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0mchosen_embedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWORD2VEC_EMBEDDINGS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mchosen_embedding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"<UNK>\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/downloader.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, return_path)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBASE_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/gensim-data/word2vec-google-news-300/__init__.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'word2vec-google-news-300'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"word2vec-google-news-300.gz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[0m\n\u001b[1;32m   1717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m         \"\"\"\n\u001b[0;32m-> 1719\u001b[0;31m         return _load_word2vec_format(\n\u001b[0m\u001b[1;32m   1720\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1721\u001b[0m             \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_header\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mno_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[0m\n\u001b[1;32m   2063\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2064\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2065\u001b[0;31m             _word2vec_read_binary(\n\u001b[0m\u001b[1;32m   2066\u001b[0m                 \u001b[0mfin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary_chunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2067\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m_word2vec_read_binary\u001b[0;34m(fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, binary_chunk_size, encoding)\u001b[0m\n\u001b[1;32m   1956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1957\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mtot_processed_words\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1958\u001b[0;31m         \u001b[0mnew_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinary_chunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1959\u001b[0m         \u001b[0mchunk\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnew_chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m         processed_words, chunk = _add_bytes_to_kv(\n",
            "\u001b[0;32m/usr/lib/python3.10/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEBADF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read() on write-only GzipFile object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/_compression.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbyte_view\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mbyte_view\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT_BUFFER_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0muncompress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconsumed_tail\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconsumed_tail\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation"
      ],
      "metadata": {
        "id": "j2lNCqWQ1HYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_result = result.get_best_result(\"loss\", mode=\"min\")\n",
        "with best_result.checkpoint.as_directory() as checkpoint_dir:\n",
        "    state_dict = torch.load(os.path.join(checkpoint_dir, \"model.pth\"))\n",
        "\n",
        "print(best_result)"
      ],
      "metadata": {
        "id": "rrnXbCrU8tFK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6bebcc9-26b1-4167-f2f7-e6790ce1aca4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result(\n",
            "  metrics={'loss': 0.6928823590278625},\n",
            "  path='/root/ray_results/tune_training_step_2024-04-23_17-59-11/tune_training_step_9b7af96a_5_batch_size=128,epochs=4,is_bidirectional=False,linear_layers=1,lr=0.0000,rnn_layers=4_2024-04-23_18-05-05',\n",
            "  filesystem='local',\n",
            "  checkpoint=Checkpoint(filesystem=local, path=/root/ray_results/tune_training_step_2024-04-23_17-59-11/tune_training_step_9b7af96a_5_batch_size=128,epochs=4,is_bidirectional=False,linear_layers=1,lr=0.0000,rnn_layers=4_2024-04-23_18-05-05/checkpoint_000000)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coded_embeddings = torch.FloatTensor(chosen_embedding.vectors).to(DEVICE)\n",
        "vocab = chosen_embedding.key_to_index\n",
        "model = OneLinearLayerGruRNN(300, 1, 300, coded_embeddings, vocab, 4, is_bidirectional=False).to(DEVICE)\n",
        "model.load_state_dict(state_dict)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErmSN1bowkQ0",
        "outputId": "c529903a-aab2-4f4b-b78e-a00c01b3adc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "torch.set_default_device(DEVICE)\n",
        "torch.set_grad_enabled(False)\n",
        "num_correct = 0\n",
        "loader = DataLoader(test_samples, batch_size=16, generator=torch.Generator(device=DEVICE))\n",
        "\n",
        "answers = torch.Tensor().to(DEVICE)\n",
        "gold_standard = torch.Tensor().to(DEVICE)\n",
        "\n",
        "for index, value in enumerate(loader):\n",
        "    data, labels = value\n",
        "    labels = labels.reshape(-1,1)\n",
        "    labels = labels.type(torch.FloatTensor)\n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    outputs = model(data)\n",
        "\n",
        "    answers = torch.cat((answers, outputs))\n",
        "    gold_standard = torch.cat((gold_standard, labels))\n",
        "\n",
        "\n",
        "torch.set_grad_enabled(True)\n",
        "accuracy = torchmetrics.Accuracy(task=\"binary\")\n",
        "mcc = torchmetrics.MatthewsCorrCoef(task=\"binary\")\n",
        "print(f\"Accuracy {accuracy(answers, gold_standard)}\")\n",
        "print(f\"MCC {mcc(answers, gold_standard)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqKXBPT7zQn9",
        "outputId": "fafe68fd-1359-47ea-a1a3-9bbaba889a45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.4399999976158142\n",
            "MCC -0.13093073666095734\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}